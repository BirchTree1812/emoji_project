{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe0b8c47",
   "metadata": {
    "papermill": {
     "duration": 0.004556,
     "end_time": "2025-12-01T11:50:49.031024",
     "exception": false,
     "start_time": "2025-12-01T11:50:49.026468",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Emoji classification\n",
    "## Imports\n",
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cdae888",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-01T11:50:49.039302Z",
     "iopub.status.busy": "2025-12-01T11:50:49.038980Z",
     "iopub.status.idle": "2025-12-01T11:51:05.852568Z",
     "shell.execute_reply": "2025-12-01T11:51:05.851194Z"
    },
    "papermill": {
     "duration": 16.819946,
     "end_time": "2025-12-01T11:51:05.854417",
     "exception": false,
     "start_time": "2025-12-01T11:50:49.034471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames[:5]: # I print 5 files per folder\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a69dc83b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:05.863892Z",
     "iopub.status.busy": "2025-12-01T11:51:05.862748Z",
     "iopub.status.idle": "2025-12-01T11:51:35.124311Z",
     "shell.execute_reply": "2025-12-01T11:51:35.123246Z"
    },
    "papermill": {
     "duration": 29.268454,
     "end_time": "2025-12-01T11:51:35.126628",
     "exception": false,
     "start_time": "2025-12-01T11:51:05.858174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mskimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m io, color\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers, models\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from skimage import io, color\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6947512d",
   "metadata": {
    "papermill": {
     "duration": 0.003767,
     "end_time": "2025-12-01T11:51:35.134476",
     "exception": false,
     "start_time": "2025-12-01T11:51:35.130709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10c3126c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:35.144206Z",
     "iopub.status.busy": "2025-12-01T11:51:35.143610Z",
     "iopub.status.idle": "2025-12-01T11:51:35.153447Z",
     "shell.execute_reply": "2025-12-01T11:51:35.152366Z"
    },
    "papermill": {
     "duration": 0.01691,
     "end_time": "2025-12-01T11:51:35.155544",
     "exception": false,
     "start_time": "2025-12-01T11:51:35.138634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_single_image(path):\n",
    "    \"\"\"\n",
    "    This will be the function you use to preprocess your image.\n",
    "    \n",
    "    \"\"\"\n",
    "    img = Image.open(path).convert(\"RGBA\")\n",
    "    img = np.array(img)\n",
    "\n",
    "    # RGBA -> RGB\n",
    "    if img.ndim == 3 and img.shape[2] == 4:\n",
    "        img = color.rgba2rgb(img) \n",
    "    # grayscale -> RGB\n",
    "    elif img.ndim == 2:\n",
    "        img = np.stack([img] * 3, axis=-1)\n",
    "\n",
    "    # unint8 conversion\n",
    "    if img.dtype != np.uint8:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "\n",
    "    # here you could add additional preprocessing\n",
    "\n",
    "    return img.astype(\"float32\") / 255.0\n",
    "\n",
    "\n",
    "def imageLoader(files, labels, batch_size):\n",
    "    \"\"\"\n",
    "    This will create a generator for learning by batches.\n",
    "    \"\"\"\n",
    "    L = len(files)\n",
    "\n",
    "    while True: \n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "\n",
    "        while batch_start < L:\n",
    "            limit = min(batch_end, L)\n",
    "\n",
    "            # Batch files (slices)\n",
    "            batch_files = files[batch_start:limit]\n",
    "\n",
    "            X_batch = []\n",
    "            y_batch = []\n",
    "\n",
    "            for f in batch_files:\n",
    "                img_id = Path(f).stem       # nom sans extension\n",
    "                img = load_single_image(f)\n",
    "                X_batch.append(img)\n",
    "                y_batch.append(labels[img_id])\n",
    "\n",
    "            X = np.stack(X_batch)\n",
    "            Y = np.array(y_batch)\n",
    "\n",
    "            yield X, Y\n",
    "\n",
    "            batch_start += batch_size\n",
    "            batch_end += batch_size\n",
    "# source code https://stackoverflow.com/questions/47200146/keras-load-images-batch-wise-for-large-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d078b9",
   "metadata": {
    "papermill": {
     "duration": 0.004142,
     "end_time": "2025-12-01T11:51:35.164144",
     "exception": false,
     "start_time": "2025-12-01T11:51:35.160002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50a6fe9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:35.173666Z",
     "iopub.status.busy": "2025-12-01T11:51:35.172746Z",
     "iopub.status.idle": "2025-12-01T11:51:35.177789Z",
     "shell.execute_reply": "2025-12-01T11:51:35.176634Z"
    },
    "papermill": {
     "duration": 0.011591,
     "end_time": "2025-12-01T11:51:35.179536",
     "exception": false,
     "start_time": "2025-12-01T11:51:35.167945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb7a5821",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:35.190065Z",
     "iopub.status.busy": "2025-12-01T11:51:35.188956Z",
     "iopub.status.idle": "2025-12-01T11:51:41.609047Z",
     "shell.execute_reply": "2025-12-01T11:51:41.607769Z"
    },
    "papermill": {
     "duration": 6.427634,
     "end_time": "2025-12-01T11:51:41.611072",
     "exception": false,
     "start_time": "2025-12-01T11:51:35.183438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dir = Path(PATH + \"train/\")\n",
    "train_files = sorted([str(p) for p in train_dir.iterdir() if p.is_file()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0172a2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:41.620701Z",
     "iopub.status.busy": "2025-12-01T11:51:41.620397Z",
     "iopub.status.idle": "2025-12-01T11:51:47.752941Z",
     "shell.execute_reply": "2025-12-01T11:51:47.751917Z"
    },
    "papermill": {
     "duration": 6.139414,
     "end_time": "2025-12-01T11:51:47.754931",
     "exception": false,
     "start_time": "2025-12-01T11:51:41.615517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dir = Path(PATH + \"test/\")\n",
    "test_files = sorted([str(p) for p in test_dir.iterdir() if p.is_file()])\n",
    "test_ids = [Path(f).stem for f in test_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "675589f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:47.766730Z",
     "iopub.status.busy": "2025-12-01T11:51:47.766404Z",
     "iopub.status.idle": "2025-12-01T11:51:47.793766Z",
     "shell.execute_reply": "2025-12-01T11:51:47.792429Z"
    },
    "papermill": {
     "duration": 0.035073,
     "end_time": "2025-12-01T11:51:47.795604",
     "exception": false,
     "start_time": "2025-12-01T11:51:47.760531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train_labels.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m y_train_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH\u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain_labels.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m y_train_dct = \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(y_train_df[\u001b[33m\"\u001b[39m\u001b[33mId\u001b[39m\u001b[33m\"\u001b[39m], y_train_df[\u001b[33m\"\u001b[39m\u001b[33mLabel\u001b[39m\u001b[33m\"\u001b[39m]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Medium_Secret/University/Programming/Python/src/venvol/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Medium_Secret/University/Programming/Python/src/venvol/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Medium_Secret/University/Programming/Python/src/venvol/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Medium_Secret/University/Programming/Python/src/venvol/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Medium_Secret/University/Programming/Python/src/venvol/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'train_labels.csv'"
     ]
    }
   ],
   "source": [
    "y_train_df = pd.read_csv(PATH+ \"train_labels.csv\")\n",
    "\n",
    "y_train_dct = dict(zip(y_train_df[\"Id\"], y_train_df[\"Label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fda3bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:47.805270Z",
     "iopub.status.busy": "2025-12-01T11:51:47.804665Z",
     "iopub.status.idle": "2025-12-01T11:51:47.811792Z",
     "shell.execute_reply": "2025-12-01T11:51:47.810132Z"
    },
    "papermill": {
     "duration": 0.014286,
     "end_time": "2025-12-01T11:51:47.813901",
     "exception": false,
     "start_time": "2025-12-01T11:51:47.799615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gen = imageLoader(\n",
    "    files=train_files,\n",
    "    labels=y_train_dct,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23e7aa7",
   "metadata": {
    "papermill": {
     "duration": 0.003681,
     "end_time": "2025-12-01T11:51:47.821889",
     "exception": false,
     "start_time": "2025-12-01T11:51:47.818208",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c023555",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:47.834550Z",
     "iopub.status.busy": "2025-12-01T11:51:47.834131Z",
     "iopub.status.idle": "2025-12-01T11:51:47.842502Z",
     "shell.execute_reply": "2025-12-01T11:51:47.841381Z"
    },
    "papermill": {
     "duration": 0.01805,
     "end_time": "2025-12-01T11:51:47.844647",
     "exception": false,
     "start_time": "2025-12-01T11:51:47.826597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_labels = y_train_df[\"Label\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2a6d84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:47.854144Z",
     "iopub.status.busy": "2025-12-01T11:51:47.853758Z",
     "iopub.status.idle": "2025-12-01T11:51:47.864613Z",
     "shell.execute_reply": "2025-12-01T11:51:47.863411Z"
    },
    "papermill": {
     "duration": 0.018326,
     "end_time": "2025-12-01T11:51:47.867010",
     "exception": false,
     "start_time": "2025-12-01T11:51:47.848684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mozilla', 'google', 'facebook', ..., 'samsung', 'facebook',\n",
       "       'facebook'], dtype='<U9')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_with_my_amazing_model(test_files):\n",
    "    prediction = np.random.choice(unique_labels, size= len(test_files))\n",
    "    ids = np.arange(1,len(test_files)+1)\n",
    "    prediction_as_df = pd.DataFrame()\n",
    "    return prediction\n",
    "\n",
    "y_test_pred = predict_with_my_amazing_model(test_files)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31300ec5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:47.877760Z",
     "iopub.status.busy": "2025-12-01T11:51:47.876306Z",
     "iopub.status.idle": "2025-12-01T11:51:47.905692Z",
     "shell.execute_reply": "2025-12-01T11:51:47.904276Z"
    },
    "papermill": {
     "duration": 0.03674,
     "end_time": "2025-12-01T11:51:47.907893",
     "exception": false,
     "start_time": "2025-12-01T11:51:47.871153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>mozilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10004</td>\n",
       "      <td>samsung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10005</td>\n",
       "      <td>google</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id     Label\n",
       "0  10001   mozilla\n",
       "1  10002    google\n",
       "2  10003  facebook\n",
       "3  10004   samsung\n",
       "4  10005    google"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids_sr = pd.Series(test_ids, name=\"Id\")\n",
    "y_test_pred_sr = pd.Series(y_test_pred, name=\"Label\")\n",
    "submission_df = pd.concat([test_ids_sr, y_test_pred_sr], axis=1)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf431098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:47.918697Z",
     "iopub.status.busy": "2025-12-01T11:51:47.918362Z",
     "iopub.status.idle": "2025-12-01T11:51:47.939475Z",
     "shell.execute_reply": "2025-12-01T11:51:47.938082Z"
    },
    "papermill": {
     "duration": 0.02915,
     "end_time": "2025-12-01T11:51:47.941734",
     "exception": false,
     "start_time": "2025-12-01T11:51:47.912584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14708949,
     "sourceId": 124850,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venvol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 67.667405,
   "end_time": "2025-12-01T11:51:50.835106",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-01T11:50:43.167701",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
