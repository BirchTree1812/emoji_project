{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe0b8c47",
   "metadata": {
    "papermill": {
     "duration": 0.004556,
     "end_time": "2025-12-01T11:50:49.031024",
     "exception": false,
     "start_time": "2025-12-01T11:50:49.026468",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Emoji Classification Project - Computer Vision**\n",
    "\n",
    "### Team Members : `Daniil NOTKIN`, `Yuhan SU` & `Yassine ERRAJI`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7386d4",
   "metadata": {},
   "source": [
    "## *Importations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdae888",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-01T11:50:49.039302Z",
     "iopub.status.busy": "2025-12-01T11:50:49.038980Z",
     "iopub.status.idle": "2025-12-01T11:51:05.852568Z",
     "shell.execute_reply": "2025-12-01T11:51:05.851194Z"
    },
    "papermill": {
     "duration": 16.819946,
     "end_time": "2025-12-01T11:51:05.854417",
     "exception": false,
     "start_time": "2025-12-01T11:50:49.034471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from skimage import io, color\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6947512d",
   "metadata": {
    "papermill": {
     "duration": 0.003767,
     "end_time": "2025-12-01T11:51:35.134476",
     "exception": false,
     "start_time": "2025-12-01T11:51:35.130709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## *Functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c3126c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:35.144206Z",
     "iopub.status.busy": "2025-12-01T11:51:35.143610Z",
     "iopub.status.idle": "2025-12-01T11:51:35.153447Z",
     "shell.execute_reply": "2025-12-01T11:51:35.152366Z"
    },
    "papermill": {
     "duration": 0.01691,
     "end_time": "2025-12-01T11:51:35.155544",
     "exception": false,
     "start_time": "2025-12-01T11:51:35.138634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_single_image(path):\n",
    "    \"\"\"\n",
    "    This will be the function you use to preprocess your image.\n",
    "    \n",
    "    \"\"\"\n",
    "    img = Image.open(path).convert(\"RGBA\")\n",
    "    img = np.array(img)\n",
    "\n",
    "    # RGBA -> RGB\n",
    "    if img.ndim == 3 and img.shape[2] == 4:\n",
    "        img = color.rgba2rgb(img) \n",
    "    # grayscale -> RGB\n",
    "    elif img.ndim == 2:\n",
    "        img = np.stack([img] * 3, axis=-1)\n",
    "\n",
    "    # unint8 conversion\n",
    "    if img.dtype != np.uint8:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "\n",
    "    # here you could add additional preprocessing\n",
    "\n",
    "    return img.astype(\"float32\") / 255.0\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Improved imageLoader \n",
    "# - shuffles every epoch\n",
    "# - resizes images\n",
    "# - optional data augmentation\n",
    "# - optional sample weights (to replace class_weight)\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "def imageLoader(\n",
    "    files,\n",
    "    labels,\n",
    "    batch_size,\n",
    "    target_size=(72, 72),\n",
    "    augment=False,\n",
    "    class_weight=None,   # NEW: dict like {class_index: weight}\n",
    "    seed=42              # NEW: for reproducibility if you want it\n",
    "):\n",
    "    \"\"\"\n",
    "    Python generator yielding:\n",
    "      - (X, y) if class_weight is None\n",
    "      - (X, y, sample_weight) if class_weight is provided\n",
    "\n",
    "    Notes:\n",
    "    - labels must be a dict: {img_id (string): label_name (string)}\n",
    "    - label_to_index must already exist in the notebook scope\n",
    "    \"\"\"\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    files = np.array(files)\n",
    "    L = len(files)\n",
    "\n",
    "    while True:\n",
    "        # Shuffle at the beginning of each epoch\n",
    "        indices = rng.permutation(L)\n",
    "        files_shuffled = files[indices]\n",
    "\n",
    "        batch_start = 0\n",
    "        while batch_start < L:\n",
    "            batch_files = files_shuffled[batch_start:batch_start + batch_size]\n",
    "\n",
    "            X_batch = np.empty((len(batch_files), target_size[1], target_size[0], 3), dtype=np.float32)\n",
    "            y_batch = np.empty((len(batch_files),), dtype=np.int32)\n",
    "\n",
    "            for i, f in enumerate(batch_files):\n",
    "                img_id = Path(f).stem  # DO NOT CHANGE (constraint)\n",
    "\n",
    "                # Load image (float32, [0,1])\n",
    "                img = load_single_image(f)\n",
    "\n",
    "                # Resize to fixed shape\n",
    "                img = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "                # Data augmentation (train only)\n",
    "                if augment:\n",
    "                    # Horizontal flip\n",
    "                    if rng.random() < 0.5:\n",
    "                        img = cv2.flip(img, 1)\n",
    "\n",
    "                    # Small rotation\n",
    "                    if rng.random() < 0.3:\n",
    "                        angle = rng.uniform(-15, 15)\n",
    "                        M = cv2.getRotationMatrix2D(\n",
    "                            (target_size[0] // 2, target_size[1] // 2),\n",
    "                            angle,\n",
    "                            1.0\n",
    "                        )\n",
    "                        img = cv2.warpAffine(\n",
    "                            img,\n",
    "                            M,\n",
    "                            (target_size[0], target_size[1]),\n",
    "                            flags=cv2.INTER_LINEAR,\n",
    "                            borderMode=cv2.BORDER_REFLECT_101\n",
    "                        )\n",
    "\n",
    "                # Store\n",
    "                X_batch[i] = img\n",
    "                y_batch[i] = label_to_index[labels[img_id]]\n",
    "\n",
    "            if class_weight is None:\n",
    "                yield X_batch, y_batch\n",
    "            else:\n",
    "                # Convert per-class weights into per-sample weights\n",
    "                sample_weight = np.array([class_weight[int(c)] for c in y_batch], dtype=np.float32)\n",
    "                yield X_batch, y_batch, sample_weight\n",
    "\n",
    "            batch_start += batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d078b9",
   "metadata": {
    "papermill": {
     "duration": 0.004142,
     "end_time": "2025-12-01T11:51:35.164144",
     "exception": false,
     "start_time": "2025-12-01T11:51:35.160002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a6fe9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:35.173666Z",
     "iopub.status.busy": "2025-12-01T11:51:35.172746Z",
     "iopub.status.idle": "2025-12-01T11:51:35.177789Z",
     "shell.execute_reply": "2025-12-01T11:51:35.176634Z"
    },
    "papermill": {
     "duration": 0.011591,
     "end_time": "2025-12-01T11:51:35.179536",
     "exception": false,
     "start_time": "2025-12-01T11:51:35.167945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = Path(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7a5821",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:35.190065Z",
     "iopub.status.busy": "2025-12-01T11:51:35.188956Z",
     "iopub.status.idle": "2025-12-01T11:51:41.609047Z",
     "shell.execute_reply": "2025-12-01T11:51:41.607769Z"
    },
    "papermill": {
     "duration": 6.427634,
     "end_time": "2025-12-01T11:51:41.611072",
     "exception": false,
     "start_time": "2025-12-01T11:51:35.183438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dir = PATH / \"train\"\n",
    "train_files = sorted([str(p) for p in train_dir.iterdir() if p.is_file()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0172a2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:41.620701Z",
     "iopub.status.busy": "2025-12-01T11:51:41.620397Z",
     "iopub.status.idle": "2025-12-01T11:51:47.752941Z",
     "shell.execute_reply": "2025-12-01T11:51:47.751917Z"
    },
    "papermill": {
     "duration": 6.139414,
     "end_time": "2025-12-01T11:51:47.754931",
     "exception": false,
     "start_time": "2025-12-01T11:51:41.615517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dir = PATH / \"test\"\n",
    "test_files = sorted([str(p) for p in test_dir.iterdir() if p.is_file()])\n",
    "test_ids = [Path(f).stem for f in test_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675589f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:47.766730Z",
     "iopub.status.busy": "2025-12-01T11:51:47.766404Z",
     "iopub.status.idle": "2025-12-01T11:51:47.793766Z",
     "shell.execute_reply": "2025-12-01T11:51:47.792429Z"
    },
    "papermill": {
     "duration": 0.035073,
     "end_time": "2025-12-01T11:51:47.795604",
     "exception": false,
     "start_time": "2025-12-01T11:51:47.760531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train_df = pd.read_csv(PATH / \"train_labels.csv\")\n",
    "\n",
    "y_train_dct = dict(zip(y_train_df[\"Id\"], y_train_df[\"Label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fda3bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:47.805270Z",
     "iopub.status.busy": "2025-12-01T11:51:47.804665Z",
     "iopub.status.idle": "2025-12-01T11:51:47.811792Z",
     "shell.execute_reply": "2025-12-01T11:51:47.810132Z"
    },
    "papermill": {
     "duration": 0.014286,
     "end_time": "2025-12-01T11:51:47.813901",
     "exception": false,
     "start_time": "2025-12-01T11:51:47.799615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gen = imageLoader(\n",
    "    files=train_files,\n",
    "    labels=y_train_dct,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23e7aa7",
   "metadata": {
    "papermill": {
     "duration": 0.003681,
     "end_time": "2025-12-01T11:51:47.821889",
     "exception": false,
     "start_time": "2025-12-01T11:51:47.818208",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc1f46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Train / Validation split\n",
    "# ============================================================\n",
    "\n",
    "# Split train files into train / validation\n",
    "train_files_split, val_files_split = train_test_split(\n",
    "    train_files,\n",
    "    test_size=0.2,        # 80% train / 20% validation\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(train_files_split)}\")\n",
    "print(f\"Validation samples: {len(val_files_split)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b2f61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = y_train_df[\"Label\"].unique().tolist()\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3f3d22",
   "metadata": {},
   "source": [
    "### Label encoding (strings → integers)\n",
    "\n",
    "Keras requires numeric labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cc28fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Convert label dict keys to STRING to match Path(f).stem\n",
    "# ============================================================\n",
    "\n",
    "labels_str = {\n",
    "    f\"{int(k):05d}\": v\n",
    "    for k, v in y_train_dct.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58beb6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Label encoding (string → integer)\n",
    "# ============================================================\n",
    "\n",
    "# Sorted for reproducibility\n",
    "unique_labels = sorted(y_train_df[\"Label\"].unique())\n",
    "\n",
    "label_to_index = {label: i for i, label in enumerate(unique_labels)}\n",
    "index_to_label = {i: label for label, i in label_to_index.items()}\n",
    "\n",
    "num_classes = len(unique_labels)\n",
    "\n",
    "print(\"Label to index mapping:\")\n",
    "print(label_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6357fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Compute class weights to handle imbalance\n",
    "# ============================================================\n",
    "\n",
    "y_encoded = [label_to_index[label] for label in y_train_df[\"Label\"]]\n",
    "\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.arange(num_classes),\n",
    "    y=y_encoded\n",
    ")\n",
    "\n",
    "class_weight = dict(enumerate(class_weights_array))\n",
    "\n",
    "print(\"Class weights:\")\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89253a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode string labels to integers\n",
    "label_to_index = {label: i for i, label in enumerate(unique_labels)}\n",
    "index_to_label = {i: label for label, i in label_to_index.items()}\n",
    "\n",
    "num_classes = len(unique_labels)\n",
    "print(label_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60d3368",
   "metadata": {},
   "source": [
    "### Define a compact, efficient CNN\n",
    "\n",
    "This model:\n",
    "\n",
    "•   Trains fast\n",
    "\n",
    "•   Fits in memory\n",
    "\n",
    "•   Should be enough for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d0649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "def build_model(input_shape=(72, 72, 3), num_classes=7):\n",
    "    \"\"\"\n",
    "    MobileNetV2-based classifier.\n",
    "    Phase 1: backbone frozen\n",
    "    Phase 2: partial fine-tuning\n",
    "    \"\"\"\n",
    "\n",
    "    # Pretrained backbone\n",
    "    base_model = MobileNetV2(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\"\n",
    "    )\n",
    "\n",
    "    # Phase 1: freeze entire backbone\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Classification head\n",
    "    x = base_model.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = models.Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4448b0",
   "metadata": {},
   "source": [
    "### **Instantiate the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b859c525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Instantiate model\n",
    "# ============================================================\n",
    "\n",
    "model = build_model(num_classes=num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b19bb6a",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "We must define steps_per_epoch manually because we use a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2a6d84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:47.854144Z",
     "iopub.status.busy": "2025-12-01T11:51:47.853758Z",
     "iopub.status.idle": "2025-12-01T11:51:47.864613Z",
     "shell.execute_reply": "2025-12-01T11:51:47.863411Z"
    },
    "papermill": {
     "duration": 0.018326,
     "end_time": "2025-12-01T11:51:47.867010",
     "exception": false,
     "start_time": "2025-12-01T11:51:47.848684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Training generators (consistent with 72x72 model input)\n",
    "# ============================================================\n",
    "\n",
    "batch_size = 32\n",
    "target_size = (72, 72)\n",
    "\n",
    "train_gen = imageLoader(\n",
    "    files=train_files_split,\n",
    "    labels=labels_str,          # keys must match Path(f).stem\n",
    "    batch_size=batch_size,\n",
    "    target_size=target_size,\n",
    "    augment=True,\n",
    "    class_weight=class_weight,  # IMPORTANT: generator will output sample weights\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_gen = imageLoader(\n",
    "    files=val_files_split,\n",
    "    labels=labels_str,\n",
    "    batch_size=batch_size,\n",
    "    target_size=target_size,\n",
    "    augment=False,\n",
    "    class_weight=None,          # no weights needed for validation\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "# Use ceil division so you don't drop the tail of the dataset\n",
    "steps_per_epoch = int(np.ceil(len(train_files_split) / batch_size))\n",
    "validation_steps = int(np.ceil(len(val_files_split) / batch_size))\n",
    "\n",
    "print(\"steps_per_epoch:\", steps_per_epoch)\n",
    "print(\"validation_steps:\", validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ecb142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Training - Phase 1 (frozen backbone)\n",
    "# ============================================================\n",
    "\n",
    "history_phase1 = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=15,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f25e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Fine-tuning - Phase 2 \n",
    "# ============================================================\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Number of layers to fine-tune from the end\n",
    "FINE_TUNE_LAYERS = 30\n",
    "\n",
    "# Freeze all layers first\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Unfreeze last N layers (except BatchNorm)\n",
    "for layer in model.layers[-FINE_TUNE_LAYERS:]:\n",
    "    if not isinstance(layer, layers.BatchNormalization):\n",
    "        layer.trainable = True\n",
    "\n",
    "# Recompile with lower learning rate (critical)\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_phase2 = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=10,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3899203",
   "metadata": {},
   "source": [
    "### **We now replace the dummy prediction function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cedba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_my_solid_model(test_files):\n",
    "    \"\"\"\n",
    "    Predict labels for the test set using the trained CNN.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "\n",
    "    for f in test_files:\n",
    "        img = load_single_image(f)\n",
    "        img = np.expand_dims(img, axis=0)  # (1, H, W, C)\n",
    "\n",
    "        probs = model.predict(img, verbose=0)\n",
    "        pred_idx = np.argmax(probs, axis=1)[0]\n",
    "        predictions.append(index_to_label[pred_idx])\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda7eb97",
   "metadata": {},
   "source": [
    "### **Generate submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31300ec5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:47.877760Z",
     "iopub.status.busy": "2025-12-01T11:51:47.876306Z",
     "iopub.status.idle": "2025-12-01T11:51:47.905692Z",
     "shell.execute_reply": "2025-12-01T11:51:47.904276Z"
    },
    "papermill": {
     "duration": 0.03674,
     "end_time": "2025-12-01T11:51:47.907893",
     "exception": false,
     "start_time": "2025-12-01T11:51:47.871153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test_pred = predict_with_my_solid_model(test_files)\n",
    "\n",
    "test_ids_sr = pd.Series(test_ids, name=\"Id\")\n",
    "y_test_pred_sr = pd.Series(y_test_pred, name=\"Label\")\n",
    "\n",
    "submission_df = pd.concat([test_ids_sr, y_test_pred_sr], axis=1)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf431098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:47.918697Z",
     "iopub.status.busy": "2025-12-01T11:51:47.918362Z",
     "iopub.status.idle": "2025-12-01T11:51:47.939475Z",
     "shell.execute_reply": "2025-12-01T11:51:47.938082Z"
    },
    "papermill": {
     "duration": 0.02915,
     "end_time": "2025-12-01T11:51:47.941734",
     "exception": false,
     "start_time": "2025-12-01T11:51:47.912584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14708949,
     "sourceId": 124850,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 67.667405,
   "end_time": "2025-12-01T11:51:50.835106",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-01T11:50:43.167701",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
