{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe0b8c47",
   "metadata": {
    "papermill": {
     "duration": 0.004556,
     "end_time": "2025-12-01T11:50:49.031024",
     "exception": false,
     "start_time": "2025-12-01T11:50:49.026468",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Emoji Classification Project - Computer Vision**\n",
    "\n",
    "### Team Members : `Daniil NOTKIN`, `Yuhan SU` & `Yassine ERRAJI`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7386d4",
   "metadata": {},
   "source": [
    "## *Importations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2cdae888",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-01T11:50:49.039302Z",
     "iopub.status.busy": "2025-12-01T11:50:49.038980Z",
     "iopub.status.idle": "2025-12-01T11:51:05.852568Z",
     "shell.execute_reply": "2025-12-01T11:51:05.851194Z"
    },
    "papermill": {
     "duration": 16.819946,
     "end_time": "2025-12-01T11:51:05.854417",
     "exception": false,
     "start_time": "2025-12-01T11:50:49.034471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from skimage import io, color\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6947512d",
   "metadata": {
    "papermill": {
     "duration": 0.003767,
     "end_time": "2025-12-01T11:51:35.134476",
     "exception": false,
     "start_time": "2025-12-01T11:51:35.130709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## *Functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c3126c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:35.144206Z",
     "iopub.status.busy": "2025-12-01T11:51:35.143610Z",
     "iopub.status.idle": "2025-12-01T11:51:35.153447Z",
     "shell.execute_reply": "2025-12-01T11:51:35.152366Z"
    },
    "papermill": {
     "duration": 0.01691,
     "end_time": "2025-12-01T11:51:35.155544",
     "exception": false,
     "start_time": "2025-12-01T11:51:35.138634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_single_image(path):\n",
    "    \"\"\"\n",
    "    This will be the function you use to preprocess your image.\n",
    "    \n",
    "    \"\"\"\n",
    "    img = Image.open(path).convert(\"RGBA\")\n",
    "    img = np.array(img)\n",
    "\n",
    "    # RGBA -> RGB\n",
    "    if img.ndim == 3 and img.shape[2] == 4:\n",
    "        img = color.rgba2rgb(img) \n",
    "    # grayscale -> RGB\n",
    "    elif img.ndim == 2:\n",
    "        img = np.stack([img] * 3, axis=-1)\n",
    "\n",
    "    # unint8 conversion\n",
    "    if img.dtype != np.uint8:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "\n",
    "    # here you could add additional preprocessing\n",
    "\n",
    "    return img.astype(\"float32\") / 255.0\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Improved imageLoader\n",
    "# - shuffles every epoch\n",
    "# - resizes images\n",
    "# - optional data augmentation\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "def imageLoader(\n",
    "    files,\n",
    "    labels,\n",
    "    batch_size,\n",
    "    target_size=(72, 72),\n",
    "    augment=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Generator yielding (X, y) batches.\n",
    "    - Ensures same image size\n",
    "    - Shuffles data each epoch\n",
    "    - Applies optional data augmentation\n",
    "    \"\"\"\n",
    "\n",
    "    files = np.array(files)\n",
    "    L = len(files)\n",
    "\n",
    "    while True:\n",
    "        # Shuffle at the beginning of each epoch\n",
    "        indices = np.random.permutation(L)\n",
    "        files = files[indices]\n",
    "\n",
    "        batch_start = 0\n",
    "\n",
    "        while batch_start < L:\n",
    "            batch_files = files[batch_start:batch_start + batch_size]\n",
    "\n",
    "            X_batch = []\n",
    "            y_batch = []\n",
    "\n",
    "            for f in batch_files:\n",
    "                img_id = Path(f).stem  # DO NOT CHANGE (constraint)\n",
    "\n",
    "                # Load image (float32, [0,1])\n",
    "                img = load_single_image(f)\n",
    "\n",
    "                # Resize to fixed shape\n",
    "                img = cv2.resize(img, target_size)\n",
    "\n",
    "                # ðŸŽ¨ Data augmentation (train only)\n",
    "                if augment:\n",
    "                    if np.random.rand() < 0.5:\n",
    "                        img = cv2.flip(img, 1)\n",
    "\n",
    "                    if np.random.rand() < 0.3:\n",
    "                        angle = np.random.uniform(-15, 15)\n",
    "                        M = cv2.getRotationMatrix2D(\n",
    "                            (target_size[0] // 2, target_size[1] // 2),\n",
    "                            angle,\n",
    "                            1.0\n",
    "                        )\n",
    "                        img = cv2.warpAffine(img, M, target_size)\n",
    "\n",
    "                X_batch.append(img)\n",
    "                y_batch.append(label_to_index[labels[img_id]])\n",
    "\n",
    "            X = np.stack(X_batch).astype(\"float32\")\n",
    "            y = np.array(y_batch, dtype=np.int32)\n",
    "\n",
    "            yield X, y\n",
    "\n",
    "            batch_start += batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d078b9",
   "metadata": {
    "papermill": {
     "duration": 0.004142,
     "end_time": "2025-12-01T11:51:35.164144",
     "exception": false,
     "start_time": "2025-12-01T11:51:35.160002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a6fe9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:35.173666Z",
     "iopub.status.busy": "2025-12-01T11:51:35.172746Z",
     "iopub.status.idle": "2025-12-01T11:51:35.177789Z",
     "shell.execute_reply": "2025-12-01T11:51:35.176634Z"
    },
    "papermill": {
     "duration": 0.011591,
     "end_time": "2025-12-01T11:51:35.179536",
     "exception": false,
     "start_time": "2025-12-01T11:51:35.167945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = Path(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7a5821",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:35.190065Z",
     "iopub.status.busy": "2025-12-01T11:51:35.188956Z",
     "iopub.status.idle": "2025-12-01T11:51:41.609047Z",
     "shell.execute_reply": "2025-12-01T11:51:41.607769Z"
    },
    "papermill": {
     "duration": 6.427634,
     "end_time": "2025-12-01T11:51:41.611072",
     "exception": false,
     "start_time": "2025-12-01T11:51:35.183438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dir = PATH / \"train\"\n",
    "train_files = sorted([str(p) for p in train_dir.iterdir() if p.is_file()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0172a2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:41.620701Z",
     "iopub.status.busy": "2025-12-01T11:51:41.620397Z",
     "iopub.status.idle": "2025-12-01T11:51:47.752941Z",
     "shell.execute_reply": "2025-12-01T11:51:47.751917Z"
    },
    "papermill": {
     "duration": 6.139414,
     "end_time": "2025-12-01T11:51:47.754931",
     "exception": false,
     "start_time": "2025-12-01T11:51:41.615517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dir = PATH / \"test\"\n",
    "test_files = sorted([str(p) for p in test_dir.iterdir() if p.is_file()])\n",
    "test_ids = [Path(f).stem for f in test_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675589f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:47.766730Z",
     "iopub.status.busy": "2025-12-01T11:51:47.766404Z",
     "iopub.status.idle": "2025-12-01T11:51:47.793766Z",
     "shell.execute_reply": "2025-12-01T11:51:47.792429Z"
    },
    "papermill": {
     "duration": 0.035073,
     "end_time": "2025-12-01T11:51:47.795604",
     "exception": false,
     "start_time": "2025-12-01T11:51:47.760531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train_df = pd.read_csv(PATH / \"train_labels.csv\")\n",
    "\n",
    "y_train_dct = dict(zip(y_train_df[\"Id\"], y_train_df[\"Label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fda3bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:47.805270Z",
     "iopub.status.busy": "2025-12-01T11:51:47.804665Z",
     "iopub.status.idle": "2025-12-01T11:51:47.811792Z",
     "shell.execute_reply": "2025-12-01T11:51:47.810132Z"
    },
    "papermill": {
     "duration": 0.014286,
     "end_time": "2025-12-01T11:51:47.813901",
     "exception": false,
     "start_time": "2025-12-01T11:51:47.799615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gen = imageLoader(\n",
    "    files=train_files,\n",
    "    labels=y_train_dct,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23e7aa7",
   "metadata": {
    "papermill": {
     "duration": 0.003681,
     "end_time": "2025-12-01T11:51:47.821889",
     "exception": false,
     "start_time": "2025-12-01T11:51:47.818208",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc1f46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Train / Validation split\n",
    "# ============================================================\n",
    "\n",
    "# Split train files into train / validation\n",
    "train_files_split, val_files_split = train_test_split(\n",
    "    train_files,\n",
    "    test_size=0.2,        # 80% train / 20% validation\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(train_files_split)}\")\n",
    "print(f\"Validation samples: {len(val_files_split)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b2f61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = y_train_df[\"Label\"].unique().tolist()\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3f3d22",
   "metadata": {},
   "source": [
    "### Label encoding (strings â†’ integers)\n",
    "\n",
    "Keras requires numeric labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cc28fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Convert label dict keys to STRING to match Path(f).stem\n",
    "# ============================================================\n",
    "\n",
    "labels_str = {\n",
    "    f\"{int(k):05d}\": v\n",
    "    for k, v in y_train_dct.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58beb6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Label encoding (string â†’ integer)\n",
    "# ============================================================\n",
    "\n",
    "# Sorted for reproducibility\n",
    "unique_labels = sorted(y_train_df[\"Label\"].unique())\n",
    "\n",
    "label_to_index = {label: i for i, label in enumerate(unique_labels)}\n",
    "index_to_label = {i: label for label, i in label_to_index.items()}\n",
    "\n",
    "num_classes = len(unique_labels)\n",
    "\n",
    "print(\"Label to index mapping:\")\n",
    "print(label_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6357fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Compute class weights to handle imbalance\n",
    "# ============================================================\n",
    "\n",
    "y_encoded = [label_to_index[label] for label in y_train_df[\"Label\"]]\n",
    "\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.arange(num_classes),\n",
    "    y=y_encoded\n",
    ")\n",
    "\n",
    "class_weight = dict(enumerate(class_weights_array))\n",
    "\n",
    "print(\"Class weights:\")\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89253a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode string labels to integers\n",
    "label_to_index = {label: i for i, label in enumerate(unique_labels)}\n",
    "index_to_label = {i: label for label, i in label_to_index.items()}\n",
    "\n",
    "num_classes = len(unique_labels)\n",
    "print(label_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c832fa00",
   "metadata": {},
   "source": [
    "### Wrap the existing generator for Keras\n",
    "\n",
    "The imageLoader already yields (X, y) â€” we just adapt labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd09fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_generator(files, labels_dict, batch_size, target_size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Wraps imageLoader to:\n",
    "    - resize images to fixed shape\n",
    "    - convert string labels to class indices\n",
    "    \"\"\"\n",
    "    base_gen = imageLoader(files, labels_dict, batch_size)\n",
    "\n",
    "    while True:\n",
    "        X, y_str = next(base_gen)\n",
    "\n",
    "        # Resize images (critical fix)\n",
    "        X_resized = np.array([\n",
    "            cv2.resize(img, target_size) for img in X\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "        # Encode labels\n",
    "        y = np.array([label_to_index[label] for label in y_str])\n",
    "\n",
    "        yield X_resized, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60d3368",
   "metadata": {},
   "source": [
    "### Define a compact, efficient CNN\n",
    "\n",
    "This model:\n",
    "\n",
    "â€¢   Trains fast\n",
    "\n",
    "â€¢   Fits in memory\n",
    "\n",
    "â€¢   Should be enough for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d0649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Build a stronger but still lightweight CNN\n",
    "# ============================================================\n",
    "\n",
    "def build_model(input_shape=(72, 72, 3), num_classes=7):\n",
    "    model = models.Sequential([\n",
    "\n",
    "        # Block 1\n",
    "        layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\", input_shape=input_shape),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        # Block 2\n",
    "        layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        # Block 3\n",
    "        layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        # Block 4 (new)\n",
    "        layers.Conv2D(256, 3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        # Head\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(256, activation=\"relu\"),\n",
    "        layers.Dropout(0.4),\n",
    "\n",
    "        layers.Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4448b0",
   "metadata": {},
   "source": [
    "### **Instantiate the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b859c525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Instantiate model\n",
    "# ============================================================\n",
    "\n",
    "model = build_model(num_classes=num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b19bb6a",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "We must define steps_per_epoch manually because we use a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2a6d84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:47.854144Z",
     "iopub.status.busy": "2025-12-01T11:51:47.853758Z",
     "iopub.status.idle": "2025-12-01T11:51:47.864613Z",
     "shell.execute_reply": "2025-12-01T11:51:47.863411Z"
    },
    "papermill": {
     "duration": 0.018326,
     "end_time": "2025-12-01T11:51:47.867010",
     "exception": false,
     "start_time": "2025-12-01T11:51:47.848684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Training (with sample weights since class_weight isn't supported for Python generators)\n",
    "# ============================================================\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1) Base generators (your imageLoader already outputs X, y with y as integer class index)\n",
    "train_gen_base = imageLoader(\n",
    "    files=train_files_split,\n",
    "    labels=labels_str,\n",
    "    batch_size=batch_size,\n",
    "    augment=True\n",
    ")\n",
    "\n",
    "val_gen = imageLoader(\n",
    "    files=val_files_split,\n",
    "    labels=labels_str,\n",
    "    batch_size=batch_size,\n",
    "    augment=False\n",
    ")\n",
    "\n",
    "# 2) Convert the class_weight dict into a vector so we can map y -> weight quickly\n",
    "#    class_weight is already computed earlier as: {0: w0, 1: w1, ...}\n",
    "class_weight_vec = np.array([class_weight[i] for i in range(num_classes)], dtype=np.float32)\n",
    "\n",
    "def add_sample_weights(gen, class_weight_vector):\n",
    "    \"\"\"\n",
    "    Wrap a (X, y) generator to yield (X, y, sample_weight).\n",
    "    sample_weight[i] = class_weight[y[i]]\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        X, y = next(gen)  # y is shape (batch,)\n",
    "        sw = class_weight_vector[y]  # shape (batch,)\n",
    "        yield X, y, sw\n",
    "\n",
    "train_gen = add_sample_weights(train_gen_base, class_weight_vec)\n",
    "\n",
    "# 3) Steps\n",
    "steps_per_epoch = len(train_files_split) // batch_size\n",
    "validation_steps = len(val_files_split) // batch_size\n",
    "\n",
    "# 4) Train (NO class_weight argument anymore)\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=20,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3899203",
   "metadata": {},
   "source": [
    "### **We now replace the dummy prediction function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cedba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_my_solid_model(test_files):\n",
    "    \"\"\"\n",
    "    Predict labels for the test set using the trained CNN.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "\n",
    "    for f in test_files:\n",
    "        img = load_single_image(f)\n",
    "        img = np.expand_dims(img, axis=0)  # (1, H, W, C)\n",
    "\n",
    "        probs = model.predict(img, verbose=0)\n",
    "        pred_idx = np.argmax(probs, axis=1)[0]\n",
    "        predictions.append(index_to_label[pred_idx])\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda7eb97",
   "metadata": {},
   "source": [
    "### **Generate submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31300ec5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:47.877760Z",
     "iopub.status.busy": "2025-12-01T11:51:47.876306Z",
     "iopub.status.idle": "2025-12-01T11:51:47.905692Z",
     "shell.execute_reply": "2025-12-01T11:51:47.904276Z"
    },
    "papermill": {
     "duration": 0.03674,
     "end_time": "2025-12-01T11:51:47.907893",
     "exception": false,
     "start_time": "2025-12-01T11:51:47.871153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test_pred = predict_with_my_solid_model(test_files)\n",
    "\n",
    "test_ids_sr = pd.Series(test_ids, name=\"Id\")\n",
    "y_test_pred_sr = pd.Series(y_test_pred, name=\"Label\")\n",
    "\n",
    "submission_df = pd.concat([test_ids_sr, y_test_pred_sr], axis=1)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf431098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:51:47.918697Z",
     "iopub.status.busy": "2025-12-01T11:51:47.918362Z",
     "iopub.status.idle": "2025-12-01T11:51:47.939475Z",
     "shell.execute_reply": "2025-12-01T11:51:47.938082Z"
    },
    "papermill": {
     "duration": 0.02915,
     "end_time": "2025-12-01T11:51:47.941734",
     "exception": false,
     "start_time": "2025-12-01T11:51:47.912584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14708949,
     "sourceId": 124850,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 67.667405,
   "end_time": "2025-12-01T11:51:50.835106",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-01T11:50:43.167701",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
